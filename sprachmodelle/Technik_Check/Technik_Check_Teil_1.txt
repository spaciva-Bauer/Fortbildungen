Vorbereitungen zur einwandfreien Funktionalität aller 
Komponenten zur Fortbildungsveranstaltung "Sprachmodelle"


Im Vorfeld wurden die benötigten Systeme auf dem eigenen Rechner installiert (siehe Anlage der Fibs-Einladung).

********************* Test der Ollama-Umgebung *********************

1.	Starten Sie die Ollama-App. Daraufhin sollte das Web-Interface der App erscheinen.

2.	Wählen Sie im Chat-Fenster zunächst das Sprachmodell gemma3:1b aus und starten Sie den Chat. 
	Im Anschluss wird zunächst das Modell heruntergeladen (778 MB), danach ist eine Kommunikation mit dem Sprachmodell möglich.


********************* Test der Python-Umgebung *********************

3.	a) Windows-Taste: Jupyter-Notebook-App starten 	(schnellerer Weg) oder 
	b) Anaconda-Navigator "launch Jupyter-Notebook" (langsamerer Weg)

4.	Sollte sich der Browser nicht selbstständig öffnen, gehen Sie bitte wie folgt vor:
	Start eines Browsers -> Zugriff auf das Jupyter-Webinterface über: http://localhost:8888/tree

5.	Laden Sie die Datei Techik_Check_Teil_2.ipynb aus dem Videostream herunter und 
	kopieren Sie diese in z.B. in das Root-Verzeichnis des Web-Servers.
	
6.	Wählen Sie in der Python-Umgebung die Datei aus (Jupyter-Notebook) uns führen Sie alle Zellen aus: 
	Menüpunkt Run -> Run all Cells

7.	Die Codezellen sollten jetzt alle ausgeführt werden. Bei der letzten Zelle muss eine Fehlermeldung erscheinen!!

10.	Open-AI-Notebook: Code-Zeile aktivieren und ausführen -> pip install openai 

11.	API-Key einfügen!

12. 	Run -> Run all Cells


